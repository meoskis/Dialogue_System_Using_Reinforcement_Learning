{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b972896",
   "metadata": {},
   "source": [
    "## Используемые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd397d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random, copy\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import copy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0847b5fc",
   "metadata": {},
   "source": [
    "## Основные настройки чат-бота"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213acd1",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "  \"db_file_paths\": {\n",
    "    \"database\": \"C:/Users/nkmeo/Course work/Datasets/movie_db.pkl\",\n",
    "    \"dict\": \"C:/Users/nkmeo/Course work/Datasets/movie_dict.pkl\",\n",
    "    \"user_goals\": \"C:/Users/nkmeo/Course work/Datasets/movie_user_goals.pkl\"\n",
    "  },\n",
    "  \"run\": {\n",
    "    \"usersim\": true,\n",
    "    \"warmup_mem\": 1000,\n",
    "    \"num_ep_run\": 20000,\n",
    "    \"train_freq\": 100,\n",
    "    \"max_round_num\": 20,\n",
    "    \"success_rate_threshold\": 0.3\n",
    "  },\n",
    "  \"agent\": {\n",
    "    \"save_weights_file_path\": \"C:/Users/nkmeo/Course work/Weights files/model.h5\",\n",
    "    \"load_weights_file_path\": \"\",\n",
    "    \"vanilla\": true,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 16,\n",
    "    \"dqn_hidden_size\": 80,\n",
    "    \"epsilon_init\": 0.0,\n",
    "    \"gamma\": 0.9,\n",
    "    \"max_mem_size\": 500000\n",
    "  },\n",
    "  \"emc\": {\n",
    "    \"slot_error_mode\": 0,\n",
    "    \"slot_error_prob\": 0.05,\n",
    "    \"intent_error_prob\": 0.0\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "___\n",
    "\n",
    "**db_file_paths** - пути к файлам с данными\n",
    "\n",
    "***database*** - база данных, в которой хранятся имеющиеся в наличие билеты\n",
    "\n",
    "***dict*** - словарь, где ключ - параметр, в значения - все возможные варианты обозначения из базы данных\n",
    "\n",
    "***user_goals*** - заранее сгенерированные ограничения и запросы пользователя для пользовательской симуляции\n",
    "___\n",
    "\n",
    "**run** - условия запуска диалоговой системы\n",
    "\n",
    "***usersim*** - true - запуск с пользовательской симуляцией / false - ручной запуск\n",
    "\n",
    "***warmup_mem*** - ограничение шагов для первичной разминки агента\n",
    "\n",
    "***num_ep_run*** - количество эпизодов (диалогов) проводимых с чат-ботом\n",
    "\n",
    "***train_freq*** - количесвто эпизодов, определяющих переодичность очистки памяти агента (если успешность в текущий период больше или равна текущему наилучшему показателю и также выше значения ***success_rate_threshold***, то память чистится с целью обучения только на более качественных результатах)\n",
    "\n",
    "***max_round_num*** - максимальное количество раундов в одном диалоге\n",
    "\n",
    "***success_rate_threshold*** - пороговое значение успешности\n",
    "___\n",
    "\n",
    "**agent** - настройки агента\n",
    "\n",
    "***save_weights_file_path*** - \"\"/\"путь\" - если присутсвует путь - сохраняет веса в указанном месте\n",
    "\n",
    "***load_weights_file_path*** - \"\"/\"путь\" - если присутсвует путь - загружает веса из указанного места\n",
    "\n",
    "***vanilla***\n",
    "\n",
    "***learning_rate*** - темп обучения для оптимизатор\n",
    "\n",
    "***batch_size*** - размер батча данных\n",
    "\n",
    "***dqn_hidden_size*** - размерность скрытого слоя\n",
    "\n",
    "***epsilon_init*** - вероятность обращения к вспомогательной модели DDQN\n",
    "\n",
    "***gamma*** - коэффициент дисконтирования уравнения Беллмана (определяет, насколько сильно агент должен учитывать будущие вознаграждения при принятии решения в настоящем)\n",
    "\n",
    "***max_mem_size*** - максимальная размерность массива памяти\n",
    "___\n",
    "**emc** - настройка модуля контроля ошибок\n",
    "\n",
    "***slot_error_mode*** - конкретно определяет ошибку, которая вносится контролером ошибок\n",
    "\n",
    "***slot_error_prob*** - вероятность не внесения ошибки (random.random() < self.slot_error_prob)\n",
    "\n",
    "***intent_error_prob*** - вероятность не внесения ошибки в намерения (random.random() < self.intent_error_prob)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d944c51a",
   "metadata": {},
   "source": [
    "## Конфигурация диалога"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b6b025",
   "metadata": {},
   "source": [
    "#### Специальные значения в слотах, котрые могут встретится:\n",
    "\n",
    "**'PLACEHOLDER'** - бозначает пустое значение (которое надо заполнить) в слотах с намерением inform\n",
    "\n",
    "**'UNK'** - Обозначает пустое значение (которое надо заполнить) в слотах с намерением request\n",
    "\n",
    "**'anything'** - Обозначает, что поле может быть заполнено любым значением (сподвигает агента к действию request)\n",
    "\n",
    "**'no match available'** - Когда состояние агента переходит в match_found (найдено совпадение), однако, ничего подходящего в БД нет\n",
    "\n",
    "#### Типы намерений:\n",
    "\n",
    "**inform** - используется с целью проинформировать собеседника об ограничении.\n",
    "\n",
    "**request** - используется с целью запроса от собеседника информации по определенному параметру.\n",
    "\n",
    "**thanks** - выражение благодарности, используемое пользователем, чтобы указать агенту, что он сделал что-то хорошее или что человек хочет завершить диалог.\n",
    "\n",
    "**match found** - используется только агентом для того, чтобы проинформировать пользователя о найденном совпадении с его целью.\n",
    "\n",
    "**reject** - используется только пользователем на действие агента с намерением **match found**, чтобы указать, что совпадение не соответствует желаниям (ограничениям) пользователя.\n",
    "\n",
    "**done** - используется только агентом, чтобы проверить достиг ли он цели пользователя по завершению диалога.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df0a1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Конфиг для симуляции пользователя  \n",
    "#######################################\n",
    "\n",
    "# Будет использоватся в контролере ошибок для добавления случайных ошибок для лучшего обучения агента\n",
    "usersim_intents = ['inform', 'request', 'thanks', 'reject', 'done']\n",
    "\n",
    "# Цель агента - следуя ограниченим достичь совпадения по этому ключу\n",
    "usersim_default_key = 'бронь'\n",
    "\n",
    "# Параметр должен быть в первом слоте с ограничением при симуляции пользователя\n",
    "usersim_required_init_inform_keys = ['кухня']\n",
    "\n",
    "#######################################\n",
    "# Конфиг агента\n",
    "#######################################\n",
    "\n",
    "# Возможные ключи слотов оганичений и запросов для агента\n",
    "# Все возможные значения ключей ограничителей слотов агента\n",
    "agent_inform_slots = ['город', 'район', 'область', 'кухня', 'название', 'яндекс_карты', 'гугл_карты', 'дата', 'время', usersim_default_key]\n",
    "                      \n",
    "# Все возможные значения ключей запросов слотов агента\n",
    "agent_request_slots = ['город', 'район', 'область', 'кухня', 'название', 'яндекс_карты', 'гугл_карты', 'дата', 'время',\n",
    "                      'количество_детей', 'количество_человек']\n",
    "\n",
    "# Возможные действия агента\n",
    "agent_actions = [\n",
    "    {'intent': 'done', 'inform_slots': {}, 'request_slots': {}},  # Инициирует завершение диалога\n",
    "    {'intent': 'match_found', 'inform_slots': {}, 'request_slots': {}} # Указывает на найденное совпадение\n",
    "]\n",
    "\n",
    "# Генерация всех возможных шаблонов действий агента (+ два действия описанные выше)...\n",
    "# ...для намерения inform\n",
    "for slot in agent_inform_slots:\n",
    "    # Пропускаем, так как намерение должно быть match_found\n",
    "    if slot == usersim_default_key:\n",
    "        continue\n",
    "    agent_actions.append({'intent': 'inform', 'inform_slots': {slot: 'PLACEHOLDER'}, 'request_slots': {}})\n",
    "\n",
    "# ...для намерения request\n",
    "for slot in agent_request_slots:\n",
    "    agent_actions.append({'intent': 'request', 'inform_slots': {}, 'request_slots': {slot: 'UNK'}})\n",
    "\n",
    "# слоты, которые будет запрашивать бот\n",
    "rule_requests = ['название', 'время', 'дата', 'город', 'район', 'количество_человек']\n",
    "\n",
    "# Значение слотов ограничений, которые не могут быть запрошены из базы данных\n",
    "no_query_keys = ['количество_детей', usersim_default_key]\n",
    "\n",
    "#######################################\n",
    "# Общий конфиг\n",
    "#######################################\n",
    "\n",
    "# Выдача оценки от симуляции пользователя для агента\n",
    "FAIL = -1\n",
    "NO_OUTCOME = 0\n",
    "SUCCESS = 1\n",
    "\n",
    "# Все возможные намерения (for one-hot conversion in ST.get_state())\n",
    "all_intents = ['inform', 'request', 'done', 'match_found', 'thanks', 'reject']\n",
    "\n",
    "# Все возможные ключи слотов (for one-hot conversion in ST.get_state())\n",
    "all_slots = ['город', 'район', 'область', 'кухня', 'название', 'яндекс_карты', 'гугл_карты', 'дата', 'время',\n",
    "            'количество_детей', 'количество_человек', usersim_default_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09fd2e5",
   "metadata": {},
   "source": [
    "## Deep Q-Network агент"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f2c94",
   "metadata": {},
   "source": [
    "#### Формулы для моделей:\n",
    "\n",
    "###### Deep Q Network (DQN)\n",
    "\n",
    "$$\n",
    "Q(s,a) \\rightarrow r + \\gamma\\cdot \\left(\\max_{a}Q\\left(s', a'\\right)\\right)\n",
    "$$\n",
    "\n",
    "$Q(s,a)$ - ожидаемая награда (значение Q-функции) для состояния s и действия a;\n",
    "\n",
    "$r$ - награда, полученная в результате выполнения действия a в состоянии s;\n",
    "\n",
    "$\\gamma$ - коэффициент дисконтирования будущих наград.\n",
    "\n",
    "$s'$ - состояние, в которое перешел агент после выполнения действия a в состоянии s;\n",
    "\n",
    "$a'$ - действие, выбранное агентом в состоянии s';\n",
    "\n",
    "$\\max_{a}Q\\left(s', a'\\right)$ - максимальное ожидаемое значение Q-функции для всех действий a' в состоянии s'.\n",
    "\n",
    "###### Double Deep Q Network (DQN)\n",
    "\n",
    "$$\n",
    "Q(s,a) \\rightarrow r + \\gamma\\cdot Q^{'}\\left(s',argmax_{a}Q\\left(s',a\\right)\\right)\n",
    "$$\n",
    "\n",
    "$Q(s,a)$ - ожидаемая награда (значение Q-функции) для состояния s и действия a;\n",
    "\n",
    "$r$ - награда, полученная в результате выполнения действия a в состоянии s;\n",
    "\n",
    "$\\gamma$ - коэффициент дисконтирования будущих наград.\n",
    "\n",
    "$s'$ - состояние, в которое перешел агент после выполнения действия a в состоянии s;\n",
    "\n",
    "$a'$ - действие, выбранное агентом в состоянии s';\n",
    "\n",
    "$argmax_{a}Q\\left(s',a\\right)$ - действие, которое максимизирует оценку Q-функции для состояния s' в первой (оценочной) нейронной сети;\n",
    "\n",
    "$Q^{'}\\left(s',argmax_{a}Q\\left(s',a\\right)\\right)$ - значения Q-функции для состояния s' и действия a', оцененные с помощью второй (таргетной) нейронной сети;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464cabf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self, state_size, constants):\n",
    "        \n",
    "        \"\"\"\n",
    "        Конструктор DQN-агента.\n",
    "        Задачи: сохранение значений-констант, настройкой нейроной сети и тд.\n",
    "        Параметры:\n",
    "            state_size (int): Размерность входящего массива состояния\n",
    "            constants (dict): Словарь с константами\n",
    "        \"\"\"\n",
    "\n",
    "        self.C = constants['agent']\n",
    "        # Массив памяти агента\n",
    "        self.memory = []\n",
    "        # Индекс в массиве памяти агента\n",
    "        self.memory_index = 0\n",
    "        # Максимальная ращмерность массива памяти\n",
    "        self.max_memory_size = self.C['max_mem_size']\n",
    "        \n",
    "        self.eps = self.C['epsilon_init']\n",
    "        \n",
    "        self.vanilla = self.C['vanilla']\n",
    "        # Темп обучения\n",
    "        self.lr = self.C['learning_rate']\n",
    "        \n",
    "        self.gamma = self.C['gamma']\n",
    "        # размерность батча\n",
    "        self.batch_size = self.C['batch_size']\n",
    "        # размерность скрытого слоя\n",
    "        self.hidden_size = self.C['dqn_hidden_size']\n",
    "\n",
    "        self.load_weights_file_path = self.C['load_weights_file_path']\n",
    "        self.save_weights_file_path = self.C['save_weights_file_path']\n",
    "\n",
    "        if self.max_memory_size < self.batch_size:\n",
    "            raise ValueError('Максимальный размер памяти должен быть не меньше размера батча!')\n",
    "\n",
    "        # размерность массива состояния\n",
    "        self.state_size = state_size\n",
    "        # возможные действия агента\n",
    "        self.possible_actions = agent_actions\n",
    "        self.num_actions = len(self.possible_actions)\n",
    "        \n",
    "        # слоты, которые будет запрашивать бот\n",
    "        self.rule_request_set = rule_requests\n",
    "\n",
    "        # Вторая модель для DDQN (для выбора действий)\n",
    "        self.beh_model = self._build_model()\n",
    "        # Модель для оценки и выбора действий для DQN\n",
    "        self.tar_model = self._build_model()\n",
    "        \n",
    "        # Загрузка имеющихся весов\n",
    "        self._load_weights()\n",
    "        \n",
    "        # Перезапуск переменных, учавствующих в подборе вариантов действий\n",
    "        self.reset()\n",
    "\n",
    "    def _build_model(self):\n",
    "        \"\"\"Строит и возвращает модель\"\"\"\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.hidden_size, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(self.num_actions, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.lr))\n",
    "        return model\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Перезапуск переменных, учавствующих в подборе вариантов действий.\"\"\"\n",
    "\n",
    "        self.rule_current_slot_index = 0\n",
    "        self.rule_phase = 'not done'\n",
    "\n",
    "    def get_action(self, state, use_rule=False):\n",
    "        \"\"\"\n",
    "        Возвращает действие агента с заданным состоянием.\n",
    "        Получает действие агента с учетом текущего состояния.\n",
    "        Для выбора состояния используется либо прописанное правило (разминка), либо модель\n",
    "        Параметры:\n",
    "            state (numpy.array): База данных в формате dict(long: dict)\n",
    "            use_rule (bool): Определяет использование прописанных правил\n",
    "            для выбора действия (для разминки перед обучением). По умолчанию: False\n",
    "            \n",
    "        Возвращает:\n",
    "            int: Индекс действия из возможных действий\n",
    "            dict: Само действие\n",
    "        \"\"\"\n",
    "        # Вероятность того, что инициализирована разминка (с выбором итогового действия) или выбор будет делать\n",
    "        #вспомогательная сеть DDQN\n",
    "        if self.eps > random.random():\n",
    "            # Выбираем рандомный индекс из возможных действий агента\n",
    "            index = random.randint(0, self.num_actions - 1)\n",
    "            # Находим значение, соответсвющее выбранному индексу\n",
    "            action = self._map_index_to_action(index)\n",
    "            return index, action\n",
    "        else:\n",
    "            # Если это разминка\n",
    "            if use_rule:\n",
    "                return self._rule_action()\n",
    "            else:\n",
    "                return self._dqn_action(state)\n",
    "\n",
    "    def _rule_action(self):\n",
    "        \"\"\"\n",
    "        Возвращает действие в соответсвии заранне прописаному правилу (для разминки).\n",
    "        Возвращает следующее действие по списку из возможных действий.\n",
    "        Возвращает:\n",
    "            int: Индекс действия из возможных действий\n",
    "            dict: Само действие\n",
    "        \"\"\"\n",
    "        \n",
    "        # Проверка на выход за рамки возможных запросов бота\n",
    "        if self.rule_current_slot_index < len(self.rule_request_set):\n",
    "            slot = self.rule_request_set[self.rule_current_slot_index]\n",
    "            self.rule_current_slot_index += 1\n",
    "            rule_response = {'intent': 'request', 'inform_slots': {}, 'request_slots': {slot: 'UNK'}}\n",
    "        elif self.rule_phase == 'not done':\n",
    "            rule_response = {'intent': 'match_found', 'inform_slots': {}, 'request_slots': {}}\n",
    "            self.rule_phase = 'done'\n",
    "        elif self.rule_phase == 'done':\n",
    "            rule_response = {'intent': 'done', 'inform_slots': {}, 'request_slots': {}}\n",
    "\n",
    "        index = self._map_action_to_index(rule_response)\n",
    "        return index, rule_response\n",
    "\n",
    "    def _map_action_to_index(self, response):\n",
    "        \"\"\"\n",
    "        Мапит соответвующий индекс к действию.\n",
    "        Параметры:\n",
    "            response (dict): ответ \n",
    "        Возвращает:\n",
    "            i (int): индекс действия\n",
    "        \"\"\"\n",
    "        \n",
    "        # Проходим по списку из всех возможных действий\n",
    "        for (i, action) in enumerate(self.possible_actions):\n",
    "            if response == action:\n",
    "                return i\n",
    "        raise ValueError(f'Ответ: {response} не найден в возможных действиях')\n",
    "\n",
    "    def _dqn_action(self, state):\n",
    "        \"\"\"\n",
    "        Возвращает индекс и само действие для вспомогательной модели для DDQN \n",
    "        Параметры:\n",
    "            state (numpy.array): База данных в формате dict(long: dict)\n",
    "        Возвращает:\n",
    "            int: Индекс действия из возможных действий\n",
    "            dict: Само действие\n",
    "        \"\"\"\n",
    "        # \n",
    "        index = np.argmax(self._dqn_predict_one(state))\n",
    "        action = self._map_index_to_action(index)\n",
    "        return index, action\n",
    "    \n",
    "    def _dqn_predict_one(self, state, target=False):\n",
    "        \"\"\"\n",
    "        Returns a model prediction given a state.\n",
    "        Parameters:\n",
    "            state (numpy.array): База данных в формате dict(long: dict)\n",
    "            target (bool)\n",
    "        Returns:\n",
    "            numpy.array\n",
    "        \"\"\"\n",
    "\n",
    "        return self._dqn_predict(state.reshape(1, self.state_size), target=target).flatten()\n",
    "\n",
    "    def _map_index_to_action(self, index):\n",
    "        \"\"\"\n",
    "        Maps an index to an action in possible actions.\n",
    "        Parameters:\n",
    "            index (int)\n",
    "        Returns:\n",
    "            dict\n",
    "        \"\"\"\n",
    "\n",
    "        for (i, action) in enumerate(self.possible_actions):\n",
    "            if index == i:\n",
    "                return copy.deepcopy(action)\n",
    "        raise ValueError(f'Индекс: {index} не найден в возможных действиях')\n",
    "\n",
    "    def _dqn_predict(self, states, target=False):\n",
    "        \"\"\"\n",
    "        Делает предсказание на основе модели.\n",
    "        Параметры:\n",
    "            states (numpy.array): : Состояние в формате dict(long: dict)\n",
    "            target (bool): определяет тип модели (DDQN или DQN)\n",
    "        Возврашает:\n",
    "            numpy.array\n",
    "        \"\"\"\n",
    "\n",
    "        if target:\n",
    "            return self.tar_model.predict(states, verbose=0)\n",
    "        else:\n",
    "            return self.beh_model.predict(states, verbose=0)\n",
    "\n",
    "    def add_experience(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        Добавляет опыт для агента на основе ходов\n",
    "        Параметры:\n",
    "            state (numpy.array): состояние\n",
    "            action (int): действие\n",
    "            reward (int): награда\n",
    "            next_state (numpy.array): следующее состояние\n",
    "            done (bool)\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.memory) < self.max_memory_size:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.memory_index] = (state, action, reward, next_state, done)\n",
    "        self.memory_index = (self.memory_index + 1) % self.max_memory_size\n",
    "\n",
    "    def empty_memory(self):\n",
    "        \"\"\"Очистка памяти агента.\"\"\"\n",
    "\n",
    "        self.memory = []\n",
    "        self.memory_index = 0\n",
    "\n",
    "    def is_memory_full(self):\n",
    "        \"\"\"Проверка на заполненность памяти.\"\"\"\n",
    "\n",
    "        return len(self.memory) == self.max_memory_size\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Обучает агента путем улучшения модели поведения на основе добавленного опыта в массив памяти.\n",
    "        Выбирает из массива памяти данные и обрабатывает их. Извлекает необходимые массивы данных\n",
    "        и высчитывает по ним уравнение Беллмана для Q-Learning.\n",
    "        \"\"\"\n",
    "\n",
    "        # Считам количество батчей\n",
    "        num_batches = len(self.memory) // self.batch_size\n",
    "        for b in range(num_batches):\n",
    "            batch = random.sample(self.memory, self.batch_size)\n",
    "            \n",
    "            # Берет все состояния из батча памяти\n",
    "            states = np.array([sample[0] for sample in batch])\n",
    "            # Берет все состояния из батча памяти\n",
    "            next_states = np.array([sample[3] for sample in batch])\n",
    "            \n",
    "            # Проверка размерности массива состояний из батчей\n",
    "            assert states.shape == (self.batch_size, self.state_size), f'Размерность состояния: {states.shape}'\n",
    "            # Проверка размерности массива будущих состояний из батчей\n",
    "            assert next_states.shape == states.shape\n",
    "            \n",
    "            # Для того, чтобы сгладить ошибку\n",
    "            beh_state_preds = self._dqn_predict(states)  # For leveling error\n",
    "            if not self.vanilla:\n",
    "                beh_next_states_preds = self._dqn_predict(next_states)  # Индексация для DDQN\n",
    "            tar_next_state_preds = self._dqn_predict(next_states, target=True)  # Для тарнет значения для DQN и DDQN\n",
    "\n",
    "            inputs = np.zeros((self.batch_size, self.state_size))\n",
    "            targets = np.zeros((self.batch_size, self.num_actions))\n",
    "            # state, action, reward, next_state, done\n",
    "            # i = индекс\n",
    "            # s = состояние (state)\n",
    "            # a = действие (action)\n",
    "            # r = награда (reward)\n",
    "            # s_ = следущее состояние (next_state)\n",
    "            # d = done\n",
    "            for i, (s, a, r, s_, d) in enumerate(batch):\n",
    "                t = beh_state_preds[i]\n",
    "                # Формулы для DDQN и DQN\n",
    "                if not self.vanilla:\n",
    "                    t[a] = r + self.gamma * tar_next_state_preds[i][np.argmax(beh_next_states_preds[i])] * (not d)\n",
    "                else:\n",
    "                    t[a] = r + self.gamma * np.amax(tar_next_state_preds[i]) * (not d)\n",
    "\n",
    "                inputs[i] = s\n",
    "                targets[i] = t\n",
    "            \n",
    "            # verbose - отключает вывод. Никакие дополнительные сообщения не будут отображаться в процессе обучения модели, кроме информации о прогрессе (progress bar), если она настроена.\n",
    "            self.beh_model.fit(inputs, targets, epochs=1, verbose=0)\n",
    "\n",
    "    def copy(self):\n",
    "        \"\"\"Копирование весов из модели поведения в таргет модель (для DDQN)\"\"\"\n",
    "        self.tar_model.set_weights(self.beh_model.get_weights())\n",
    "\n",
    "    def save_weights(self):\n",
    "        \"\"\"Сохранение весов для обоих моделей в формате .h5.\"\"\"\n",
    "        if not self.save_weights_file_path:\n",
    "            return\n",
    "        beh_save_file_path = re.sub(r'\\.h5', r'_beh.h5', self.load_weights_file_path)\n",
    "        self.beh_model.save_weights(filepath=beh_save_file_path,save_format='h5')\n",
    "        tar_save_file_path = re.sub(r'\\.h5', r'_tar.h5', self.load_weights_file_path)\n",
    "        self.tar_model.save_weights(filepath=tar_save_file_path,save_format='h5')\n",
    "\n",
    "    def _load_weights(self):\n",
    "        \"\"\"Загрузка весов для обоих моделей в формате .h5.\"\"\"\n",
    "\n",
    "        if not self.load_weights_file_path:\n",
    "            return\n",
    "        beh_load_file_path = re.sub(r'\\.h5', r'_beh.h5', self.load_weights_file_path)\n",
    "        self.beh_model.load_weights(beh_load_file_path)\n",
    "        tar_load_file_path = re.sub(r'\\.h5', r'_tar.h5', self.load_weights_file_path)\n",
    "        self.tar_model.load_weights(tar_load_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3379d0",
   "metadata": {},
   "source": [
    "## Трекер состояния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37b5239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateTracker:\n",
    "    \"\"\"Отслеживает состояние диалога и подготавливает представление состояния для агента.\"\"\"\n",
    "\n",
    "    def __init__(self, database, constants):\n",
    "        \n",
    "        \"\"\"\n",
    "        Конструктор Трекера состояний.\n",
    "        Создает запросы к базе данных, необходимые агенту представления состояния.\n",
    "        Параметры:\n",
    "            database (dict): База данных в формате dict(long: dict).\n",
    "            constants (dict): Константы из файла с конфигурацией.\n",
    "        \"\"\"\n",
    "        # Объект для совершения запросов к базе данных\n",
    "        self.db_helper = DBQuery(database)\n",
    "        # Цель агента - следуя ограниченим достичь совпадения по этому ключу\n",
    "        self.match_key = usersim_default_key\n",
    "        # Словарь со всеми намерениями\n",
    "        self.intents_dict = convert_list_to_dict(all_intents)\n",
    "        self.num_intents = len(all_intents)\n",
    "        \n",
    "        # Словарь со всеми ключами слотов\n",
    "        self.slots_dict = convert_list_to_dict(all_slots)\n",
    "        self.num_slots = len(all_slots)\n",
    "        \n",
    "        # Максимальное количество раундов в диалоге\n",
    "        self.max_round_num = constants['run']['max_round_num']\n",
    "        \n",
    "        # Пустой массив размерности массива состояния\n",
    "        self.none_state = np.zeros(self.get_state_size())\n",
    "        self.reset()\n",
    "        \n",
    "\n",
    "    def get_state_size(self):\n",
    "        \"\"\"Возвращает размер состояния в представлении агента\"\"\"\n",
    "        \n",
    "        # 2 * self.num_intents - все слоты информации/ограничения произведенные пользователем и агентом\n",
    "        # 7 * self.num_slots - определяется различными типами сохраненной информации (далее будет описано подробнее)\n",
    "        # 3 - этап диалога\n",
    "        # max_round_num - Максимальное количество раундов в диалоге\n",
    "        return 2 * self.num_intents + 7 * self.num_slots + 3 + self.max_round_num\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Очистка слотов текущих слотов ограничений, истории и номера раунда.\"\"\"\n",
    "        \n",
    "        self.current_informs = {}\n",
    "        self.history = []\n",
    "        self.round_num = 0\n",
    "\n",
    "    def print_history(self):\n",
    "        \"\"\"Вспомогательная функция отображающая историю действий.\"\"\"\n",
    "\n",
    "        for action in self.history:\n",
    "            print(action)\n",
    "\n",
    "    def get_state(self, done=False):\n",
    "        \"\"\"\n",
    "        Возвращает представление состояния в виде массива numpy, который передается в нейронную сеть агента.\n",
    "        Представление состояния содержит полезную для агента информацию о текущем состоянии диалога.\n",
    "        Параметры:\n",
    "            done (bool): Указывает является ли этот раунд последним в диалоге. По умолчанию: False\n",
    "        Returns:\n",
    "            numpy.array: Пустой массив формы (state_size,)\n",
    "            или\n",
    "            numpy.array: массив (state_size,)\n",
    "        \"\"\"\n",
    "\n",
    "        # Если это конечный раунд - заполнение нулями\n",
    "        if done:\n",
    "            return self.none_state\n",
    "\n",
    "        user_action = self.history[-1]\n",
    "        # \n",
    "        db_results_dict = self.db_helper.get_db_results_for_slots(self.current_informs)\n",
    "        last_agent_action = self.history[-2] if len(self.history) > 1 else None\n",
    "        \n",
    "        # 1\n",
    "        # Создает one-hot для параметров, чтобы отобразить текущее действие пользователя\n",
    "        user_act_rep = np.zeros((self.num_intents,))\n",
    "        user_act_rep[self.intents_dict[user_action['intent']]] = 1.0\n",
    "        \n",
    "        # 2\n",
    "        # Создает массив данных слотов ограничений, чтобы отобразить текущее действие пользователя\n",
    "        user_inform_slots_rep = np.zeros((self.num_slots,))\n",
    "        for key in user_action['inform_slots'].keys():\n",
    "            user_inform_slots_rep[self.slots_dict[key]] = 1.0\n",
    "        \n",
    "        # 3\n",
    "        # Создает массив данных слотов представлений, чтобы отобразить текущее действие пользователя\n",
    "        user_request_slots_rep = np.zeros((self.num_slots,))\n",
    "        for key in user_action['request_slots'].keys():\n",
    "            user_request_slots_rep[self.slots_dict[key]] = 1.0\n",
    "        \n",
    "        # 4\n",
    "        # Создает массив с заполненными слотами на основе current_slots\n",
    "        current_slots_rep = np.zeros((self.num_slots,))\n",
    "        for key in self.current_informs:\n",
    "            current_slots_rep[self.slots_dict[key]] = 1.0\n",
    "\n",
    "        # 5\n",
    "        #  Кодирование последнего намерения агента\n",
    "        agent_act_rep = np.zeros((self.num_intents,))\n",
    "        if last_agent_action:\n",
    "            agent_act_rep[self.intents_dict[last_agent_action['intent']]] = 1.0\n",
    "        \n",
    "        # 6\n",
    "        # Кодирование последнего слота оганичения агента\n",
    "        agent_inform_slots_rep = np.zeros((self.num_slots,))\n",
    "        if last_agent_action:\n",
    "            for key in last_agent_action['inform_slots'].keys():\n",
    "                agent_inform_slots_rep[self.slots_dict[key]] = 1.0\n",
    "\n",
    "        # 7\n",
    "        # Кодирование последнего слота запроса агента\n",
    "        agent_request_slots_rep = np.zeros((self.num_slots,))\n",
    "        if last_agent_action:\n",
    "            for key in last_agent_action['request_slots'].keys():\n",
    "                agent_request_slots_rep[self.slots_dict[key]] = 1.0\n",
    "\n",
    "        # Численное представление номера раунда\n",
    "        turn_rep = np.zeros((1,)) + self.round_num / 5.\n",
    "\n",
    "        # One-hot представление номера раунда\n",
    "        turn_onehot_rep = np.zeros((self.max_round_num,))\n",
    "        turn_onehot_rep[self.round_num - 1] = 1.0\n",
    "\n",
    "        # Представление результатов запроса к БД (отмасштабированные)\n",
    "        kb_count_rep = np.zeros((self.num_slots + 1,)) + db_results_dict['matching_all_constraints'] / 100.\n",
    "        for key in db_results_dict.keys():\n",
    "            if key in self.slots_dict:\n",
    "                kb_count_rep[self.slots_dict[key]] = db_results_dict[key] / 100.\n",
    "\n",
    "        # Представление результатов запроса к БД (бинарные)\n",
    "        kb_binary_rep = np.zeros((self.num_slots + 1,)) + np.sum(db_results_dict['matching_all_constraints'] > 0.)\n",
    "        for key in db_results_dict.keys():\n",
    "            if key in self.slots_dict:\n",
    "                kb_binary_rep[self.slots_dict[key]] = np.sum(db_results_dict[key] > 0.)\n",
    "\n",
    "        # объеденение в один массив данных размерности get_state_size(self)\n",
    "        state_representation = np.hstack(\n",
    "            [user_act_rep, user_inform_slots_rep, user_request_slots_rep, agent_act_rep, agent_inform_slots_rep,\n",
    "             agent_request_slots_rep, current_slots_rep, turn_rep, turn_onehot_rep, kb_binary_rep,\n",
    "             kb_count_rep]).flatten()\n",
    "\n",
    "        return state_representation\n",
    "\n",
    "    def update_state_agent(self, agent_action):\n",
    "        \"\"\"\n",
    "        Обновляет историю диалога действиями агента и дополняет действие агента.\n",
    "        Принимает действие агента и обновляет историю. Также дополняет параметр agent_action информацией о запросе\n",
    "        и любой другой необходимой информацией.\n",
    "        Параметры:\n",
    "            agent_action (dict): Действие агента в формате dict('intent': string, 'inform_slots': dict,\n",
    "                                 'request_slots': dict) и изменяется к dict('intent': '', 'inform_slots': {},\n",
    "                                 'request_slots': {}, 'round': int, 'спикер': 'Agent')\n",
    "        \"\"\"\n",
    "\n",
    "        if agent_action['intent'] == 'inform':\n",
    "            # Проверка, что ограничение непустое\n",
    "            assert agent_action['inform_slots']\n",
    "            # заполняет текущие слоты значениями из базы данных\n",
    "            inform_slots = self.db_helper.fill_inform_slot(agent_action['inform_slots'], self.current_informs)\n",
    "            agent_action['inform_slots'] = inform_slots\n",
    "            # Проверка, что ограничение непустое\n",
    "            assert agent_action['inform_slots']\n",
    "            key, value = list(agent_action['inform_slots'].items())[0]  # Берем только одно\n",
    "            # Проверка на найденное совпадение\n",
    "            assert key != 'match_found'\n",
    "            # Проверка на наличие конкретного значения\n",
    "            assert value != 'PLACEHOLDER', f'KEY: {key}'\n",
    "            self.current_informs[key] = value\n",
    "        # Если намерение match_found, тогда все ограничения действия заполняются с подобранными ограничениями (если совпадение вообще нашлось)\n",
    "        elif agent_action['intent'] == 'match_found':\n",
    "            assert not agent_action['inform_slots'], 'Невозможно передать ограничение при действии match_found!'\n",
    "            # Достаем конечные значения для действия match_found\n",
    "            db_results = self.db_helper.get_db_results(self.current_informs)\n",
    "            if db_results:\n",
    "                # Произвольно выбирается первое значение из словаря\n",
    "                key, value = list(db_results.items())[0]\n",
    "                agent_action['inform_slots'] = copy.deepcopy(value)\n",
    "                agent_action['inform_slots'][self.match_key] = str(key)\n",
    "            else:\n",
    "                agent_action['inform_slots'][self.match_key] = 'no match available'\n",
    "            self.current_informs[self.match_key] = agent_action['inform_slots'][self.match_key]\n",
    "        agent_action.update({'round': self.round_num, 'спикер': 'Агент'})\n",
    "        self.history.append(agent_action)\n",
    "\n",
    "    def update_state_user(self, user_action):\n",
    "        \"\"\"\n",
    "        Обновляет историю диалогов действиями пользователя и дополняет действие пользователя.\n",
    "        Принимает действие пользователя и обновляет историю. Также дополняет параметр user_action необходимой информацией.\n",
    "        Параметры:\n",
    "            user_action (dict): Действие пользователя в формате dict('intent': string, 'inform_slots': dict,\n",
    "                                 'request_slots': dict) и изменяется к dict('intent': '', 'inform_slots': {},\n",
    "                                 'request_slots': {}, 'round': int, 'speaker': 'User')\n",
    "        \"\"\"\n",
    "\n",
    "        for key, value in user_action['inform_slots'].items():\n",
    "            self.current_informs[key] = value\n",
    "        user_action.update({'round': self.round_num, 'сприкер': 'Пользователь'})\n",
    "        self.history.append(user_action)\n",
    "        self.round_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbaeca8",
   "metadata": {},
   "source": [
    "## Запросы к базе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "364e3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBQuery:\n",
    "    \"\"\"Осуществляет запросы к базе данных для трекера состояния.\"\"\"\n",
    "\n",
    "    def __init__(self, database):\n",
    "        \"\"\"\n",
    "        Состав DBQuery.\n",
    "        Параметры:\n",
    "            database (dict): База данных в формате dict(long: dict)\n",
    "        \"\"\"\n",
    "\n",
    "        self.database = database\n",
    "        # {frozenset: {string: int}} Словарь словарей (frozenset - ключ значение текущих слотов ограничения (далее будет описано))\n",
    "        self.cached_db_slot = defaultdict(dict)\n",
    "        # {frozenset: {'#': {'slot': 'value'}}} Словарь словарей словарей, словарь подсловарей базы данных\n",
    "        self.cached_db = defaultdict(dict)\n",
    "        # Значение слотов ограничений, которые не могут быть запрошены из базы данных\n",
    "        self.no_query = no_query_keys\n",
    "        # Цель агента - следуя ограниченим достичь совпадения по этому ключу\n",
    "        self.match_key = usersim_default_key\n",
    "    \n",
    "    def fill_inform_slot(self, inform_slot_to_fill, current_inform_slots):\n",
    "        \"\"\"\n",
    "        Для текущих слотов ограничений и констант заполняет ограничения, которые должны быть заполнены значениями\n",
    "        из базы данных.\n",
    "        Выполняет поиск в базе данных, чтобы заполнить слоты ограничений с значением \"PLACEHOLDER\"\n",
    "        значениями, которые даются в текущими константами в текущем эпизоде.\n",
    "        Параметры:\n",
    "            inform_slot_to_fill (dict): Слоты ограничения, которые будут заполнены ограничениями\n",
    "            current_inform_slots (dict): Текущие слоты ограничения с значениями из трекера состояний\n",
    "        Возвращает:\n",
    "            dict: inform_slot_to_fill заполненый значениями\n",
    "        \"\"\"\n",
    "\n",
    "        # По простой системе к заполнению подается толлько один слот ограничение\n",
    "        assert len(inform_slot_to_fill) == 1\n",
    "        \n",
    "        key = list(inform_slot_to_fill.keys())[0]\n",
    "\n",
    "        # Если ограничение, которое мы хотим заполнить содержится в текущих ограничениях - удаляем его для перезапроса\n",
    "        current_informs = copy.deepcopy(current_inform_slots)\n",
    "        current_informs.pop(key, None)\n",
    "\n",
    "        # db_results это словарь словарей, аналогичный словарю базы данных (просто подмножество)\n",
    "        # ищем подходящие варианты заполнения текущих ограничений\n",
    "        db_results = self.get_db_results(current_informs)\n",
    "\n",
    "        filled_inform = {}\n",
    "        # Подсчитываем количество совпадений по ключу, который хотим заполнить\n",
    "        values_dict = self._count_slot_values(key, db_results)\n",
    "        if values_dict:\n",
    "            # Выбираем наиболее часто встречающийся ключ (т.е. значение слота с наибольшим количеством доступных результатов)\n",
    "            filled_inform[key] = max(values_dict, key=values_dict.get)\n",
    "        else:\n",
    "            filled_inform[key] = 'no match available'\n",
    "\n",
    "        return filled_inform\n",
    "\n",
    "    def _count_slot_values(self, key, db_subdict):\n",
    "        \"\"\"\n",
    "        Возвращает список значений и количества вхождений каждого из них, учитывая ключ из базы данных\n",
    "        Параметры:\n",
    "            key (string): Ключ для подсчета\n",
    "            db_subdict (dict): подсловарь из базы данных\n",
    "        Возвращает:\n",
    "            dict: Значения и их вхождения по ключу\n",
    "        \"\"\"\n",
    "\n",
    "        slot_values = defaultdict(int)  # Обнуляем вывод\n",
    "        for id in db_subdict.keys():\n",
    "            current_option_dict = db_subdict[id]\n",
    "            # Если есть совпадение по ключу\n",
    "            if key in current_option_dict.keys():\n",
    "                slot_value = current_option_dict[key]\n",
    "                slot_values[slot_value] += 1\n",
    "        return slot_values\n",
    "\n",
    "    def get_db_results(self, constraints):\n",
    "        \n",
    "        \"\"\"\n",
    "        Получает все элементы в базе данных, соответствующие текущим ограничениям.\n",
    "        Просматривает каждый элемент в базе данных, и если его слоты содержат все ограничения и их значения\n",
    "        совпадают, то элемент добавляется в возвращаемый список.\n",
    "        Параметры:\n",
    "            constraints (dict): Текущие ограничения\n",
    "        Возвращает:\n",
    "            dict: Доступные значения из базы данных\n",
    "        \"\"\"\n",
    "        \n",
    "        # Отфильтровывает незапрашиваемые элементы и ключи со значением 'anything', поскольку они не имеют отношения к ограничениям.\n",
    "        new_constraints = {k: v for k, v in constraints.items() if k != self.no_query and v != 'anything'}\n",
    "\n",
    "        inform_items = frozenset(new_constraints.items())\n",
    "        cache_return = self.cached_db[inform_items]\n",
    "\n",
    "        if cache_return == None:\n",
    "            # Если значение пустое, то нет совпадений по текущим константам - возвращаем пустой словарь\n",
    "            return {}\n",
    "        # Если не пустое - возвращаем то, что в нем есть\n",
    "        if cache_return:\n",
    "            return cache_return\n",
    "        # В иных же случаях:\n",
    "        \n",
    "        # Словарь с возможными вариантами заполнения\n",
    "        available_options = {}\n",
    "        # Проходим по словарю из билетов\n",
    "        for id in self.database.keys():\n",
    "            # Выбираем словарь с вариантом заполнения\n",
    "            current_option_dict = self.database[id]\n",
    "            # Проверяем, содержатся ли в выбранном варианте ключи слотов ограничений\n",
    "            # Примечание: это предполагает, что если ограничение не найдено в элементе БД, то этот элемент не соответствует\n",
    "            if len(set(new_constraints.keys()) - set(self.database[id].keys())) == 0:\n",
    "                match = True\n",
    "                # Теперь проверяем каждое значение (новых ограничений) на наличие в базе данных\n",
    "                for k, v in new_constraints.items():\n",
    "                    if str(v) != str(current_option_dict[k]):\n",
    "                        match = False\n",
    "                if match:\n",
    "                    # Обновляем кэш с возможно подходящим словарем(билетом)\n",
    "                    self.cached_db[inform_items].update({id: current_option_dict})\n",
    "                    available_options.update({id: current_option_dict})\n",
    "\n",
    "        # Если нет подходящих вариантов заполнения, то устанавляется значение Nonr в кеше\n",
    "        if not available_options:\n",
    "            self.cached_db[inform_items] = None\n",
    "\n",
    "        return available_options\n",
    "\n",
    "    def get_db_results_for_slots(self, current_informs):\n",
    "        \"\"\"\n",
    "        Подсчитывает количество вхождений каждого текущего слота информации (ключ и значение) в элементах\n",
    "        базы данных.\n",
    "        Для каждого элемента в базе данных и каждого текущего информационного слота, если этот слот находится\n",
    "        в базе данных (соответствует ключу и значению), то счетчик увеличивается на 1.\n",
    "        Параметры:\n",
    "            current_informs (dict): Текущие ограничения и константы из конфига\n",
    "        Возвращает:\n",
    "            dict: Ключи в current_informs с количеством совпадений в базе данных по этому ключу.\n",
    "        \"\"\"\n",
    "\n",
    "        # Значения (ключ, значение) текущих слотов ограничения, которые будут использоватся как ключ для cached_db_slot\n",
    "        inform_items = frozenset(current_informs.items())\n",
    "        # Словарь с ключами ограничениями и их количеством в порядке как были сохранены (или нет) в cached_db_slot\n",
    "        cache_return = self.cached_db_slot[inform_items]\n",
    "        \n",
    "        # Если cache_return пустой, то возвращаем\n",
    "        if cache_return:\n",
    "            return cache_return\n",
    "\n",
    "        # Если прошел проверку, значит был сделан новый запрос и необходимо добавит его в cached_db_slot и вернуть его\n",
    "        # Обнуление счетсика всех результатов поиска\n",
    "        db_results = {key: 0 for key in current_informs.keys()}\n",
    "        db_results['matching_all_constraints'] = 0\n",
    "\n",
    "        for id in self.database.keys():\n",
    "            all_slots_match = True\n",
    "            for CI_key, CI_value in current_informs.items():\n",
    "                # Пропустить, если ключ является незапршиваемым\n",
    "                if CI_key in self.no_query:\n",
    "                    continue\n",
    "                if CI_value == 'anything':\n",
    "                    db_results[CI_key] += 1\n",
    "                    continue\n",
    "                if CI_key in self.database[id].keys():\n",
    "                    if CI_value == self.database[id][CI_key]:\n",
    "                        db_results[CI_key] += 1\n",
    "                    else:\n",
    "                        all_slots_match = False\n",
    "                else:\n",
    "                    all_slots_match = False\n",
    "            if all_slots_match:\n",
    "                db_results['matching_all_constraints'] += 1\n",
    "\n",
    "        # Обновление кеша\n",
    "        self.cached_db_slot[inform_items].update(db_results)\n",
    "        assert self.cached_db_slot[inform_items] == db_results\n",
    "        return db_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a85987",
   "metadata": {},
   "source": [
    "## Настройки пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ad65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    \"\"\"Позволяет реальному пользователю проводить диалоги с ботом.\"\"\"\n",
    "\n",
    "    def __init__(self, constants):\n",
    "        \"\"\"\n",
    "        Состав для User.\n",
    "        Параметры:\n",
    "            constants (dict): загружает ограничения конфига в словарь\n",
    "        \"\"\"\n",
    "        self.max_round = constants['run']['max_round_num']\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Перезапускает пользователя.\n",
    "        Возвращает:\n",
    "            dict: ответ пользователя\n",
    "        \"\"\"\n",
    "\n",
    "        return self._return_response()\n",
    "\n",
    "    def _return_response(self):\n",
    "        \"\"\"\n",
    "        Запрашивает ответ от пользователя и принимает его на вход.\n",
    "        Формат должен быть примерно следующим:\n",
    "        Формат примерно следующий:\n",
    "        request/район: солнцево, дата: пятница/кухня\n",
    "        or done//\n",
    "        намерения, слоты ограничений и запросов не могут содержать \"/,:\"\n",
    "        Возвращает:\n",
    "            dict: Ответ пользователя\n",
    "        \"\"\"\n",
    "\n",
    "        response = {'intent': '', 'inform_slots': {}, 'request_slots': {}}\n",
    "        while True:\n",
    "            input_string = input('Response: ')\n",
    "            chunks = input_string.split('/')\n",
    "\n",
    "            intent_correct = True\n",
    "            if chunks[0] not in usersim_intents:\n",
    "                intent_correct = False\n",
    "            response['intent'] = chunks[0]\n",
    "\n",
    "            informs_correct = True\n",
    "            if len(chunks[1]) > 0:\n",
    "                informs_items_list = chunks[1].split(', ')\n",
    "                for inf in informs_items_list:\n",
    "                    inf = inf.split(': ')\n",
    "                    if inf[0] not in all_slots:\n",
    "                        informs_correct = False\n",
    "                        break\n",
    "                    response['inform_slots'][inf[0]] = inf[1]\n",
    "\n",
    "            requests_correct = True\n",
    "            if len(chunks[2]) > 0:\n",
    "                requests_key_list = chunks[2].split(', ')\n",
    "                for req in requests_key_list:\n",
    "                    if req not in all_slots:\n",
    "                        requests_correct = False\n",
    "                        break\n",
    "                    response['request_slots'][req] = 'UNK'\n",
    "\n",
    "            if intent_correct and informs_correct and requests_correct:\n",
    "                break\n",
    "\n",
    "        return response\n",
    "\n",
    "    def _return_success(self):\n",
    "        \"\"\"\n",
    "        Спрашивает пользователя оценку дейстыия бота (-1, 0 или 1 (проигрыш, ничья, победа))\n",
    "        Возвращает:\n",
    "            int: Показатель успеха: -1, 0 или 1 (проигрыш, ничья, победа)\n",
    "        \"\"\"\n",
    "        success = -2\n",
    "        while success not in (-1, 0, 1):\n",
    "            success = int(input('Успех?: '))\n",
    "        return success\n",
    "\n",
    "    def step(self, agent_action):\n",
    "        \"\"\"\n",
    "        Возвращает ответ пользователя, награду и индекс успешности\n",
    "        Параметры:\n",
    "            agent_action (dict): Текущее действие агента\n",
    "        Возвращает:\n",
    "            dict: Ответ пользователя\n",
    "            int: Награду\n",
    "            bool: флаг завершения\n",
    "            int: Успех: -1, 0 или 1 (проигрыш, ничья, победа)\n",
    "        \"\"\"\n",
    "\n",
    "        # Assertions ----\n",
    "        # в ограничениях не должно быть неопределенности\n",
    "        for value in agent_action['inform_slots'].values():\n",
    "            assert value != 'UNK'\n",
    "            assert value != 'PLACEHOLDER'\n",
    "        # \n",
    "        # PLACEHOLDER не должно быть в слотах запросов\n",
    "        for value in agent_action['request_slots'].values():\n",
    "            assert value != 'PLACEHOLDER'\n",
    "        # ---------------\n",
    "\n",
    "        print(f'Действие Агента: {agent_action}')\n",
    "\n",
    "        done = False\n",
    "        user_response = {'intent': '', 'request_slots': {}, 'inform_slots': {}}\n",
    "\n",
    "        # Проверка на ограничение по количеству раундов\n",
    "        if agent_action['round'] == self.max_round:\n",
    "            success = FAIL\n",
    "            user_response['intent'] = 'done'\n",
    "        else:\n",
    "            user_response = self._return_response()\n",
    "            success = self._return_success()\n",
    "\n",
    "        if success == FAIL or success == SUCCESS:\n",
    "            done = True\n",
    "\n",
    "        assert 'UNK' not in user_response['inform_slots'].values()\n",
    "        assert 'PLACEHOLDER' not in user_response['request_slots'].values()\n",
    "\n",
    "        reward = reward_function(success, self.max_round)\n",
    "\n",
    "        return user_response, reward, done, True if success == 1 else False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b2a9a2",
   "metadata": {},
   "source": [
    "## Симуляция пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17ae395",
   "metadata": {},
   "source": [
    "Симуляция пользователя необходима чтобы предобучить модель для дальнейшего использования обычными пользователями.\n",
    "\n",
    "Симуляция пользователя будет строится на основе agenda-based системы (системы \"на основе повестки дня\"). Это означает, что у пользователя есть цель в диалоге, и он предпринимает действия в соответствии с этой целью, отслеживая при этом текущее состояние разговора, чтобы в дальнейшем предпринимать обоснованные действия.\n",
    "\n",
    "На каждом этапе диалога действие пользователя создается в ответ на действие агента (бота) с использованием в основном детерминированных правил, а также нескольких стохастических правил для создания разнообразия ответов.\n",
    "\n",
    "Внутреннее состояние пользовательского симулятора отслеживает как целевые слоты, так и историю текущего разговора. Эта информация используется для создания действий пользователя на каждом этапе. В частности, состояние представляет собой список из 4 словарей слотов и намерения:\n",
    "\n",
    "    1) rest_slots - слоты информирования и запросов от цели, которые еще не были упомянуты ни агентом, ни пользователем.\n",
    "    \n",
    "    2) history_slots - все информационные слоты от действий пользователя и агента до текущего момента.\n",
    "    \n",
    "    3) inform_slots - слоты запросов, которые пользователь хочет запросить в ближайших или будущих действиях.\n",
    "    \n",
    "    4) request_slots - слоты с информацией, который пользователь намеревается сообщить в ближайшем действии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e314a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserSimulator:\n",
    "    \"\"\"Симуляция реального пользователя для обучения агента средствами RL\"\"\"\n",
    "\n",
    "    def __init__(self, goal_list, constants, database):\n",
    "        \"\"\"\n",
    "        Состав UserSimulator. Устанавливает переменные конфигурации диалога.\n",
    "        Параметры:\n",
    "            goal_list (list): Цели пользователя загруженные из файла\n",
    "            constants (dict): Константы, загруженные из конфига\n",
    "            database (dict): База данных в формате dict(long: dict)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Цели пользователя загруженные из файла\n",
    "        self.goal_list = goal_list\n",
    "        # Максимальное количество раундов из конфига\n",
    "        self.max_round = constants['run']['max_round_num']\n",
    "        # Целевой ключ\n",
    "        self.default_key = usersim_default_key\n",
    "        # Список необходимых параметров, которые должны быть использованы в первых действиях\n",
    "        self.init_informs = usersim_required_init_inform_keys\n",
    "        # Параметры не подлежащие запросу\n",
    "        self.no_query = no_query_keys\n",
    "        self.database = database\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Перезапуск симуляции пользователя путем очистки вектора состояния.\n",
    "        Возвращает:\n",
    "            dict: Начальное действие в диалоге.\n",
    "        \"\"\"\n",
    "        self.goal = random.choice(self.goal_list)\n",
    "        # Добавить слот по умолчанию в запросы\n",
    "        self.goal['request_slots'][self.default_key] = 'UNK'\n",
    "        self.state = {}\n",
    "        # Добавляет переданные ограничения в сим-пользователем или агентом в этот словарь\n",
    "        self.state['history_slots'] = {}\n",
    "        # Добавление слотов ограничений, занесенных в историю, сообщенных пользователем и агентом. Изначально пустое.\n",
    "        self.state['inform_slots'] = {}\n",
    "        # Текущие слоты запросов, которые хочет запросит сим-пользователь.\n",
    "        self.state['request_slots'] = {}\n",
    "        \n",
    "        # Cлоты информирования и запросов от цели, которые еще не были проинформированы ни агентом, ни пользователем.\n",
    "        self.state['rest_slots'] = {}\n",
    "        self.state['rest_slots'].update(self.goal['inform_slots'])\n",
    "        self.state['rest_slots'].update(self.goal['request_slots'])\n",
    "        self.state['intent'] = ''\n",
    "        # False отвечает за неудачу, true для успеха, изначально: неудача\n",
    "        self.constraint_check = FAIL\n",
    "\n",
    "        return self._return_init_action()\n",
    "\n",
    "    def _return_init_action(self):\n",
    "        \"\"\"\n",
    "        Возвращает начальное действие эпизода. Для инициализации требуется слоты ограничения  и один запрашиваемый слот.\n",
    "        Возвращает:\n",
    "            dict: Изначальный ответ сим-пользователя\n",
    "        \"\"\"\n",
    "\n",
    "        # Всегда request\n",
    "        self.state['intent'] = 'request'\n",
    "\n",
    "        if self.goal['inform_slots']:\n",
    "            # Выбираем все необходимые инициализируемые ограничения и добавляем их к слотам ограничений (в случае наличия)\n",
    "            for inform_key in self.init_informs:\n",
    "                if inform_key in self.goal['inform_slots']:\n",
    "                    self.state['inform_slots'][inform_key] = self.goal['inform_slots'][inform_key]\n",
    "                    self.state['rest_slots'].pop(inform_key)\n",
    "                    self.state['history_slots'][inform_key] = self.goal['inform_slots'][inform_key]\n",
    "            # В случае, если ничего не было выбрано, то выюирается рандомный вариант\n",
    "            if not self.state['inform_slots']:\n",
    "                key, value = random.choice(list(self.goal['inform_slots'].items()))\n",
    "                self.state['inform_slots'][key] = value\n",
    "                self.state['rest_slots'].pop(key)\n",
    "                self.state['history_slots'][key] = value\n",
    "        \n",
    "        # Теперь добавляем действие запроса. В случае, если в цели нету слота запроса, то выбираем дефолтный параметр для запроса.\n",
    "        self.goal['request_slots'].pop(self.default_key)\n",
    "        if self.goal['request_slots']:\n",
    "            req_key = random.choice(list(self.goal['request_slots'].keys()))\n",
    "        else:\n",
    "            req_key = self.default_key\n",
    "        self.goal['request_slots'][self.default_key] = 'UNK'\n",
    "        self.state['request_slots'][req_key] = 'UNK'\n",
    "        \n",
    "        # Формируем первый ответ пользователя\n",
    "        user_response = {}\n",
    "        user_response['intent'] = self.state['intent']\n",
    "        user_response['request_slots'] = copy.deepcopy(self.state['request_slots'])\n",
    "        user_response['inform_slots'] = copy.deepcopy(self.state['inform_slots'])\n",
    "\n",
    "        return user_response\n",
    "\n",
    "    def step(self, agent_action):\n",
    "        \"\"\"\n",
    "        Возвращает ответ от сим-пользователя агенту используя некоторые правилла симуляции пользователя.\n",
    "        Учитывая некоторые детерминированные правила, которые симулирует пользователя, заставляет агента генерировать ответ.\n",
    "        Некоторые из этих правил вероятностные.\n",
    "        Параметры:\n",
    "            agent_action (dict): Действие агента, а которое отвечает пользовательская симуляция\n",
    "        Возвращает:\n",
    "            dict: Ответ пользовательской симуляции\n",
    "            int: Награда\n",
    "            bool: Done flag\n",
    "            int: Success: -1, 0 или 1 (проигрыш, ничья, победа)\n",
    "        \"\"\"\n",
    "\n",
    "        # Некоторые условия  -----\n",
    "        # В действиях агента не должно быть UNK (в слотах ограничениях)\n",
    "        for value in agent_action['inform_slots'].values():\n",
    "            assert value != 'UNK'\n",
    "            assert value != 'PLACEHOLDER'\n",
    "        # В действиях агента не должно быть PLACEHOLDER (в слотах запросов)\n",
    "        for value in agent_action['request_slots'].values():\n",
    "            assert value != 'PLACEHOLDER'\n",
    "        # ----------------\n",
    "\n",
    "        self.state['inform_slots'].clear()\n",
    "        self.state['intent'] = ''\n",
    "\n",
    "        done = False\n",
    "        success = NO_OUTCOME\n",
    "        # Проверка номера раунда в диалоге\n",
    "        if agent_action['round'] == self.max_round:\n",
    "            done = True\n",
    "            success = FAIL\n",
    "            self.state['intent'] = 'done'\n",
    "            self.state['request_slots'].clear()\n",
    "        else:\n",
    "        \n",
    "        # Генерируем ответ на основе намерения агента\n",
    "            agent_intent = agent_action['intent']\n",
    "            if agent_intent == 'request':\n",
    "                self._response_to_request(agent_action)\n",
    "            elif agent_intent == 'inform':\n",
    "                self._response_to_inform(agent_action)\n",
    "            elif agent_intent == 'match_found':\n",
    "                self._response_to_match_found(agent_action)\n",
    "            elif agent_intent == 'done':\n",
    "                success = self._response_to_done()\n",
    "                self.state['intent'] = 'done'\n",
    "                self.state['request_slots'].clear()\n",
    "                done = True\n",
    "\n",
    "        # Проверки -------\n",
    "        # Если намерение request, тогда необходимо убедиться, что слоты с запросами есть\n",
    "        if self.state['intent'] == 'request':\n",
    "            assert self.state['request_slots']\n",
    "        # Если намерение inform, тогда необходимо убедиться, что слоты с информацией/ограничениями вообще есть\n",
    "        if self.state['intent'] == 'inform':\n",
    "            assert self.state['inform_slots']\n",
    "            assert not self.state['request_slots']\n",
    "        # Проверка на пустые значения для разных намерений\n",
    "        assert 'UNK' not in self.state['inform_slots'].values()\n",
    "        assert 'PLACEHOLDER' not in self.state['request_slots'].values()\n",
    "        # Совпадений между массивами информации rest_slots и history_slots не должны быть\n",
    "        for key in self.state['rest_slots']:\n",
    "            assert key not in self.state['history_slots']\n",
    "        for key in self.state['history_slots']:\n",
    "            assert key not in self.state['rest_slots']\n",
    "        # Все слоты в rest_slots и history_slots должны содержать слоты для цели\n",
    "        for inf_key in self.goal['inform_slots']:\n",
    "            assert self.state['history_slots'].get(inf_key, False) or self.state['rest_slots'].get(inf_key, False)\n",
    "        for req_key in self.goal['request_slots']:\n",
    "            assert self.state['history_slots'].get(req_key, False) or self.state['rest_slots'].get(req_key,False), req_key\n",
    "        # Все что содержится в rest_slots должно быть в целевом массиве\n",
    "        for key in self.state['rest_slots']:\n",
    "            assert self.goal['inform_slots'].get(key, False) or self.goal['request_slots'].get(key, False)\n",
    "        assert self.state['intent'] != ''\n",
    "        # -----------------------\n",
    "\n",
    "        # Генерация ответа\n",
    "        user_response = {}\n",
    "        user_response['intent'] = self.state['intent']\n",
    "        user_response['request_slots'] = copy.deepcopy(self.state['request_slots'])\n",
    "        user_response['inform_slots'] = copy.deepcopy(self.state['inform_slots'])\n",
    "        \n",
    "        # Вычисляем награду\n",
    "        reward = reward_function(success, self.max_round)\n",
    "\n",
    "        return user_response, reward, done, True if success == 1 else False\n",
    "\n",
    "    def _response_to_request(self, agent_action):\n",
    "        \"\"\"\n",
    "        Дополняет состояние в ответ на действия агента с намерением request.\n",
    "        Существует 4 основных ситуаций для ответа\n",
    "        Параметры:\n",
    "            agent_action (dict): Намерение запроса в стандартной форме (включая 'speaker': 'Agent' и 'round_num': int)\n",
    "        \"\"\"\n",
    "        \n",
    "        agent_request_key = list(agent_action['request_slots'].keys())[0]\n",
    "        # Первый случай: Если агент запрашивает что-то, что находится в слотах ограничениях цели,\n",
    "        # и оно не было проинформировано, то информируйте об этом из самой цели.\n",
    "        if agent_request_key in self.goal['inform_slots']:\n",
    "            self.state['intent'] = 'inform'\n",
    "            self.state['inform_slots'][agent_request_key] = self.goal['inform_slots'][agent_request_key]\n",
    "            self.state['request_slots'].clear()\n",
    "            self.state['rest_slots'].pop(agent_request_key, None)\n",
    "            self.state['history_slots'][agent_request_key] = self.goal['inform_slots'][agent_request_key]\n",
    "        # Второй случай: Если агент запрашивает что-то, что находится в слотах запроса цели, и он уже был проинформирован,\n",
    "        # то сообщите об этом из истории\n",
    "        elif agent_request_key in self.goal['request_slots'] and agent_request_key in self.state['history_slots']:\n",
    "            self.state['intent'] = 'inform'\n",
    "            self.state['inform_slots'][agent_request_key] = self.state['history_slots'][agent_request_key]\n",
    "            self.state['request_slots'].clear()\n",
    "            assert agent_request_key not in self.state['rest_slots']\n",
    "        # Третий случай: Если агент запрашивает что-то, что находится в слотах запроса цели, и он до этого не был\n",
    "        # проинформирован, то производиться запрос того же слота со случайной информацией.\n",
    "        elif agent_request_key in self.goal['request_slots'] and agent_request_key in self.state['rest_slots']:\n",
    "            self.state['request_slots'].clear()\n",
    "            self.state['intent'] = 'request'\n",
    "            self.state['request_slots'][agent_request_key] = 'UNK'\n",
    "            rest_informs = {}\n",
    "            for key, value in list(self.state['rest_slots'].items()):\n",
    "                if value != 'UNK':\n",
    "                    rest_informs[key] = value\n",
    "            if rest_informs:\n",
    "                key_choice, value_choice = random.choice(list(rest_informs.items()))\n",
    "                self.state['inform_slots'][key_choice] = value_choice\n",
    "                self.state['rest_slots'].pop(key_choice)\n",
    "                self.state['history_slots'][key_choice] = value_choice\n",
    "        # Четвертый случай: В иных вариантах симулятор пользователя не придает значение о запрашиваемом слоте;\n",
    "        # передается что угодно в качестве запрошенного слота.\n",
    "        else:\n",
    "            assert agent_request_key not in self.state['rest_slots']\n",
    "            self.state['intent'] = 'inform'\n",
    "            self.state['inform_slots'][agent_request_key] = 'anything'\n",
    "            self.state['request_slots'].clear()\n",
    "            self.state['history_slots'][agent_request_key] = 'anything'\n",
    "\n",
    "    def _response_to_inform(self, agent_action):\n",
    "        \"\"\"\n",
    "        Дополняет состояние в ответ на действия агента с намерением inform.\n",
    "        Существует 2 основных ситуаций для ответа.\n",
    "        Параметры:\n",
    "            agent_action (dict): Намерение inform в стандартной форме действия format (включая 'speaker': 'Agent' и\n",
    "                                 'round_num': int)\n",
    "        \"\"\"\n",
    "\n",
    "        agent_inform_key = list(agent_action['inform_slots'].keys())[0]\n",
    "        agent_inform_value = agent_action['inform_slots'][agent_inform_key]\n",
    "\n",
    "        assert agent_inform_key != self.default_key\n",
    "\n",
    "        # Добавляет ограничения сим-пользователя и агента в history_slots\n",
    "        self.state['history_slots'][agent_inform_key] = agent_inform_value\n",
    "        # Убирает те же слоты, которые были добавлены в историю\n",
    "        self.state['rest_slots'].pop(agent_inform_key, None)\n",
    "        # Убмрает значение inform если оно оказалось в слотах запросов\n",
    "        self.state['request_slots'].pop(agent_inform_key, None)\n",
    "\n",
    "        # Первый случай: Если агент сообщает что-то, что находится в цели, и значение, которое он сообщил,\n",
    "        # не совпадает, то сообщается правильное значение\n",
    "        if agent_inform_value != self.goal['inform_slots'].get(agent_inform_key, agent_inform_value):\n",
    "            self.state['intent'] = 'inform'\n",
    "            self.state['inform_slots'][agent_inform_key] = self.goal['inform_slots'][agent_inform_key]\n",
    "            self.state['request_slots'].clear()\n",
    "            self.state['history_slots'][agent_inform_key] = self.goal['inform_slots'][agent_inform_key]\n",
    "        # Второй случай: В противном случае выберается какой-либо слот для информирования:\n",
    "        else:\n",
    "            # - Если есть что-то в слоте запроса - запрашивается\n",
    "            if self.state['request_slots']:\n",
    "                self.state['intent'] = 'request'\n",
    "            # - В ином случе, если есть что-то в \"остальных\" слотах - берется\n",
    "            elif self.state['rest_slots']:\n",
    "                def_in = self.state['rest_slots'].pop(self.default_key, False)\n",
    "                if self.state['rest_slots']:\n",
    "                    key, value = random.choice(list(self.state['rest_slots'].items()))\n",
    "                    if value != 'UNK':\n",
    "                        self.state['intent'] = 'inform'\n",
    "                        self.state['inform_slots'][key] = value\n",
    "                        self.state['rest_slots'].pop(key)\n",
    "                        self.state['history_slots'][key] = value\n",
    "                    else:\n",
    "                        self.state['intent'] = 'request'\n",
    "                        self.state['request_slots'][key] = 'UNK'\n",
    "                else:\n",
    "                    self.state['intent'] = 'request'\n",
    "                    self.state['request_slots'][self.default_key] = 'UNK'\n",
    "                if def_in == 'UNK':\n",
    "                    self.state['rest_slots'][self.default_key] = 'UNK'\n",
    "            # - В противном случае ответьте «спасибо», что на самом деле означает «нечего сказать»\n",
    "            else:\n",
    "                self.state['intent'] = 'thanks'\n",
    "\n",
    "    def _response_to_match_found(self, agent_action):\n",
    "        \n",
    "        \"\"\"\n",
    "        Дополняет состояние в ответ на действия агента с намерением match_found.\n",
    "        Проверяет если ли совпадение в действии агента, которое работает для текущей цели.\n",
    "        Параметры:\n",
    "            agent_action (dict): Намерение match_found в стандартной форме действие (включая 'speaker': 'Agent' и\n",
    "                                 'round_num': int)\n",
    "        \"\"\"\n",
    "        \n",
    "        agent_informs = agent_action['inform_slots']\n",
    "\n",
    "        self.state['intent'] = 'thanks'\n",
    "        self.constraint_check = SUCCESS\n",
    "        \n",
    "        # Проверка есть ли ключ по умолчанию в ограничениях\n",
    "        assert self.default_key in agent_informs\n",
    "        self.state['rest_slots'].pop(self.default_key, None)\n",
    "        self.state['history_slots'][self.default_key] = str(agent_informs[self.default_key])\n",
    "        self.state['request_slots'].pop(self.default_key, None)\n",
    "\n",
    "        if agent_informs[self.default_key] == 'no match available':\n",
    "            self.constraint_check = FAIL\n",
    "        \n",
    "        # Проверяет все ли ограничения цели есть в ограничениях агента\n",
    "        for key, value in self.goal['inform_slots'].items():\n",
    "            assert value != None\n",
    "            # Для параметров не подлежащих завпросам проверка не производится\n",
    "            if key in self.no_query:\n",
    "                continue\n",
    "            # Вернет True если ключа нет в ограничениях агента или если значение не совпадает с informs[key] агента\n",
    "            if value != agent_informs.get(key, None):\n",
    "                self.constraint_check = FAIL\n",
    "                break\n",
    "\n",
    "        if self.constraint_check == FAIL:\n",
    "            self.state['intent'] = 'reject'\n",
    "            self.state['request_slots'].clear()\n",
    "\n",
    "    def _response_to_done(self):\n",
    "        \"\"\"\n",
    "        Дополняет состояние в ответ на действия агента с намерением done.\n",
    "        Если constraint_check = SUCCESS, тогда rest_slots и request_slots должны быть пустыми для того,\n",
    "        чтобы эпизод можно было считать успешным.\n",
    "        Возвращает:\n",
    "            int: Success: -1, 0 или 1 (проигрыш, ничья, победа)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.constraint_check == FAIL:\n",
    "            return FAIL\n",
    "\n",
    "        if not self.state['rest_slots']:\n",
    "            assert not self.state['request_slots']\n",
    "        if self.state['rest_slots']:\n",
    "            return FAIL\n",
    "\n",
    "        # TEMP: ----\n",
    "        assert self.state['history_slots'][self.default_key] != 'no match available'\n",
    "\n",
    "        match = copy.deepcopy(self.database[int(self.state['history_slots'][self.default_key])])\n",
    "\n",
    "        for key, value in self.goal['inform_slots'].items():\n",
    "            assert value != None\n",
    "            if key in self.no_query:\n",
    "                continue\n",
    "            if value != match.get(key, None):\n",
    "                assert True == False, f'match: {match}\\ngoal: {self.goal}'\n",
    "                break\n",
    "        # ----------\n",
    "\n",
    "        return SUCCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba79e52",
   "metadata": {},
   "source": [
    "## Модуль контроля ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac876dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorModelController:\n",
    "    \"\"\"Добавляет ошибку в действие пользователя\"\"\"\n",
    "\n",
    "    def __init__(self, db_dict, constants):\n",
    "        \"\"\"\n",
    "        Состав ErrorModelController.\n",
    "        Параметры:\n",
    "            db_dict (dict): База данных в формате dict(string: list), где каждый ключ это название слота и\n",
    "            список возможных его значений\n",
    "            constants (dict): Загружает констианты из json\n",
    "        \"\"\"\n",
    "\n",
    "        self.movie_dict = db_dict\n",
    "        self.slot_error_prob = constants['emc']['slot_error_prob']\n",
    "        self.slot_error_mode = constants['emc']['slot_error_mode']  # [0, 3]\n",
    "        self.intent_error_prob = constants['emc']['intent_error_prob']\n",
    "        self.intents = usersim_intents\n",
    "\n",
    "    def infuse_error(self, frame):\n",
    "        \"\"\" \n",
    "        Принимает массив действия и добавляет в него \"ошибку\"\n",
    "        В словарь добавляется ошибка в соотвествии с указанными параметрами в константах.\n",
    "        Given a dict/frame it adds error based on specifications in constants.\n",
    "        Возможно замена значения слота, полная замена слота, удаление слота или все сразу.\n",
    "        Параметры:\n",
    "            frame (dict): формат dict('intent': '', 'inform_slots': {}, 'request_slots': {}, 'round': int,\n",
    "                          'speaker': 'User')\n",
    "        \"\"\"\n",
    "\n",
    "        informs_dict = frame['inform_slots']\n",
    "        for key in list(frame['inform_slots'].keys()):\n",
    "            assert key in self.movie_dict\n",
    "            if random.random() < self.slot_error_prob:\n",
    "                if self.slot_error_mode == 0:  # заменяет только значения слота\n",
    "                    self._slot_value_noise(key, informs_dict)\n",
    "                elif self.slot_error_mode == 1:  # полностью заменяет слот\n",
    "                    self._slot_noise(key, informs_dict)\n",
    "                elif self.slot_error_mode == 2:  # удаляет слот\n",
    "                    self._slot_remove(key, informs_dict)\n",
    "                else:  # совмещает все вместе\n",
    "                    rand_choice = random.random()\n",
    "                    if rand_choice <= 0.33:\n",
    "                        self._slot_value_noise(key, informs_dict)\n",
    "                    elif rand_choice > 0.33 and rand_choice <= 0.66:\n",
    "                        self._slot_noise(key, informs_dict)\n",
    "                    else:\n",
    "                        self._slot_remove(key, informs_dict)\n",
    "        if random.random() < self.intent_error_prob:  # добавляет ошибку на уровень намерения\n",
    "            frame['intent'] = random.choice(self.intents)\n",
    "\n",
    "    def _slot_value_noise(self, key, informs_dict):\n",
    "        \"\"\"\n",
    "        Выбирает новое значение для коюча в слоте для замены\n",
    "        Параметры:\n",
    "            key (string)\n",
    "            informs_dict (dict)\n",
    "        \"\"\"\n",
    "\n",
    "        informs_dict[key] = random.choice(self.movie_dict[key])\n",
    "\n",
    "    def _slot_noise(self, key, informs_dict):\n",
    "        \"\"\"\n",
    "        Заменяет текущий слот\n",
    "        Заменяет текущий слот с заданным ключом в словаре inform новым слотом\n",
    "        Параметры:\n",
    "            key (string)\n",
    "            informs_dict (dict)\n",
    "        \"\"\"\n",
    "\n",
    "        informs_dict.pop(key)\n",
    "        random_slot = random.choice(list(self.movie_dict.keys()))\n",
    "        informs_dict[random_slot] = random.choice(self.movie_dict[random_slot])\n",
    "\n",
    "    def _slot_remove(self, key, informs_dict):\n",
    "        \"\"\"\n",
    "        Удаляет слот\n",
    "        Параметры:\n",
    "            key (string)\n",
    "            informs_dict (dict)\n",
    "        \"\"\"\n",
    "\n",
    "        informs_dict.pop(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60cd832",
   "metadata": {},
   "source": [
    "## Дополнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01407c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_dict(lst):\n",
    "    \"\"\"\n",
    "    Конвертирует список в словарь, где ключи это список элементоа и значения это индексы элементов в списке\n",
    "    Параметры:\n",
    "        lst (list)\n",
    "    Возвращает:\n",
    "        dict\n",
    "    \"\"\"\n",
    "\n",
    "    if len(lst) > len(set(lst)):\n",
    "        raise ValueError('Список должен быть уникальным!')\n",
    "    return {k: v for v, k in enumerate(lst)}\n",
    "\n",
    "\n",
    "def remove_empty_slots(dic):\n",
    "    \"\"\"\n",
    "    Удаляет все пучтые слоты\n",
    "    Параметры:\n",
    "        dic (dict)\n",
    "    \"\"\"\n",
    "\n",
    "    for id in list(dic.keys()):\n",
    "        for key in list(dic[id].keys()):\n",
    "            if dic[id][key] == '':\n",
    "                dic[id].pop(key)\n",
    "\n",
    "\n",
    "def reward_function(success, max_round):\n",
    "    \"\"\"\n",
    "    Функция наград.\n",
    "    Возврвщвет -1 + -max_round если неудача, -1 + 2 * max_round, если успех и -1 в ином случае.\n",
    "    Параметры:\n",
    "        success (int)\n",
    "    Возвращает:\n",
    "        int: награда\n",
    "    \"\"\"\n",
    "\n",
    "    reward = -1\n",
    "    if success == FAIL:\n",
    "        reward += -max_round\n",
    "    elif success == SUCCESS:\n",
    "        reward += 2 * max_round\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26ba3b9",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSTANTS_FILE_PATH = \"C:/Users/nkmeo/kudryashov_course_work/notebooks_and_program/dialog_run/constants.json\"\n",
    "\n",
    "with open(CONSTANTS_FILE_PATH, \"r\") as read_file:\n",
    "    constants = json.load(read_file)\n",
    "\n",
    "# Параметры путей к файлам\n",
    "file_path_dict = constants['db_file_paths']\n",
    "DATABASE_FILE_PATH = file_path_dict['database']\n",
    "DICT_FILE_PATH = file_path_dict['dict']\n",
    "USER_GOALS_FILE_PATH = file_path_dict['user_goals']\n",
    "\n",
    "# Параметры запуска\n",
    "run_dict = constants['run']\n",
    "USE_USERSIM = run_dict['usersim']\n",
    "WARMUP_MEM = run_dict['warmup_mem']\n",
    "NUM_EP_TRAIN = run_dict['num_ep_run']\n",
    "TRAIN_FREQ = run_dict['train_freq']\n",
    "MAX_ROUND_NUM = run_dict['max_round_num']\n",
    "SUCCESS_RATE_THRESHOLD = run_dict['success_rate_threshold']\n",
    "\n",
    "# Загрзка базы данных\n",
    "database = pickle.load(open(DATABASE_FILE_PATH, 'rb'), encoding='latin1')\n",
    "\n",
    "# Очистка базы данных\n",
    "remove_empty_slots(database)\n",
    "\n",
    "# Загруска словаря данных\n",
    "db_dict = pickle.load(open(DICT_FILE_PATH, 'rb'), encoding='latin1')\n",
    "\n",
    "# Загрузка файлов цели\n",
    "user_goals = pickle.load(open(USER_GOALS_FILE_PATH, 'rb'), encoding='latin1')\n",
    "\n",
    "if USE_USERSIM:\n",
    "    user = UserSimulator(user_goals, constants, database)\n",
    "else:\n",
    "    user = User(constants)\n",
    "emc = ErrorModelController(db_dict, constants)\n",
    "state_tracker = StateTracker(database, constants)\n",
    "dqn_agent = DQNAgent(state_tracker.get_state_size(), constants)\n",
    "\n",
    "# Запуск раунда\n",
    "def run_round(state, warmup=False):\n",
    "    # 1) Агент выполняет действие с учетом данных из трекера состояния диалога.\n",
    "    agent_action_index, agent_action = dqn_agent.get_action(state, use_rule=warmup)\n",
    "    # 2) Обновление трекера состояния действием агента\n",
    "    state_tracker.update_state_agent(agent_action)\n",
    "    # 3) Пользоваель выполняет действие\n",
    "    user_action, reward, done, success = user.step(agent_action)\n",
    "    if not done:\n",
    "        # 4) Добавляет ошибку, если диалог не завершен\n",
    "        emc.infuse_error(user_action)\n",
    "    # 5) Обновляет трекер состояния действием агента\n",
    "    state_tracker.update_state_user(user_action)\n",
    "    # 6) Получает новое состояние и обновляет опыт\n",
    "    next_state = state_tracker.get_state(done)\n",
    "    dqn_agent.add_experience(state, agent_action_index, reward, next_state, done)\n",
    "\n",
    "    return next_state, reward, done, success\n",
    "\n",
    "\n",
    "def warmup_run():\n",
    "    \"\"\"\n",
    "    Запускает этап разминки, для первичного заполнения памяти агента\n",
    "    Агент использует заранее прописанную политику действий. Память агента заполняется при выполнении \n",
    "    Цикл завершается, когда размер памяти становится равным WARMUP_MEM или когда буфер памяти заполняется.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Тренировка началась...')\n",
    "    total_step = 0\n",
    "    start = time.time()\n",
    "    while total_step != WARMUP_MEM and not dqn_agent.is_memory_full():\n",
    "        # Перезапуск эпизода\n",
    "        episode_reset()\n",
    "        done = False\n",
    "        # Получение начального состояния от трекера\n",
    "        state = state_tracker.get_state()\n",
    "        while not done:\n",
    "            next_state, _, done, _ = run_round(state, warmup=True)\n",
    "            total_step += 1\n",
    "            state = next_state\n",
    "\n",
    "    print(f'...Тренировка закончилась {time.time()-start}')\n",
    "\n",
    "\n",
    "def train_run():\n",
    "    \"\"\"\n",
    "    Запускает цикл обучения агента\n",
    "    Обучение нейронной сети агента происходит каждый раз, когда TRAIN_FREQ кратно указанному значению.\n",
    "    Прекращается, когда серия достигает NUM_EP_TRAIN.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Обучение началось...')\n",
    "    episode = 0\n",
    "    period_reward_total = 0\n",
    "    period_success_total = 0\n",
    "    success_rate_best = 0.0\n",
    "    \n",
    "    success_rate_by_period = {}\n",
    "    success_rate_best_period = {}\n",
    "    period_reward_total_period = {}\n",
    "    \n",
    "    while episode < NUM_EP_TRAIN:\n",
    "        start = time.time()\n",
    "        episode_reset()\n",
    "        episode += 1\n",
    "        done = False\n",
    "        state = state_tracker.get_state()\n",
    "        while not done:\n",
    "            next_state, reward, done, success = run_round(state)\n",
    "            period_reward_total += reward\n",
    "            state = next_state\n",
    "\n",
    "        period_success_total += success\n",
    "\n",
    "        # Обчучение\n",
    "        if episode % TRAIN_FREQ == 0:\n",
    "            # Проверка вероятности успеха\n",
    "            success_rate = period_success_total / TRAIN_FREQ\n",
    "            avg_reward = period_reward_total / TRAIN_FREQ\n",
    "            # Очистка памяти\n",
    "            if success_rate >= success_rate_best and success_rate >= SUCCESS_RATE_THRESHOLD:\n",
    "                dqn_agent.empty_memory()\n",
    "            # Обновление лучшей вероятности успеха\n",
    "            if success_rate > success_rate_best:\n",
    "                print(f'Эпизод: {episode} НОВЫЙ ЛУЧШИЙ ПОКАЗАТЕЛЬ УСПЕХА: {success_rate} Средняя награда: {avg_reward}')\n",
    "                success_rate_best = success_rate\n",
    "                dqn_agent.save_weights()\n",
    "            \n",
    "            success_rate_by_period[episode] = success_rate\n",
    "            success_rate_best_period[episode] = success_rate_best\n",
    "            period_reward_total_period[episode] = avg_reward\n",
    "            period_success_total = 0\n",
    "            period_reward_total = 0\n",
    "            # Копирование\n",
    "            dqn_agent.copy()\n",
    "            # Обучение\n",
    "            dqn_agent.train()\n",
    "        print(f'Эпизод: {episode} - {time.time()-start}')\n",
    "    print('...Обучение завершено')\n",
    "    \n",
    "    return(success_rate_by_period, success_rate_best_period, period_reward_total_period)\n",
    "\n",
    "def episode_reset():\n",
    "    \"\"\"\n",
    "    Перезапуск эпизода в разминке и обучении\n",
    "    \"\"\"\n",
    "\n",
    "    # Перезапуск трекера состояния\n",
    "    state_tracker.reset()\n",
    "    # Выбирается инициализирующее действие пользователя\n",
    "    user_action = user.reset()\n",
    "    # Обновление ошибки\n",
    "    emc.infuse_error(user_action)\n",
    "    # Обновляется трекер состояния\n",
    "    state_tracker.update_state_user(user_action)\n",
    "    # Обновление агента\n",
    "    dqn_agent.reset()\n",
    "    \n",
    "warmup_run()\n",
    "a, b, c = train_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f735cfb",
   "metadata": {},
   "source": [
    "## Запуск в тестовом режиме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSTANTS_FILE_PATH = r'C:\\Users\\nkmeo\\kudryashov_course_work\\notebooks_and_program\\dialog_run\\constants.json'\n",
    "\n",
    "with open(CONSTANTS_FILE_PATH, \"r\") as read_file:\n",
    "    constants = json.load(read_file)\n",
    "\n",
    "# Загрузка путей к файлам\n",
    "file_path_dict = constants['db_file_paths']\n",
    "DATABASE_FILE_PATH = file_path_dict['database']\n",
    "DICT_FILE_PATH = file_path_dict['dict']\n",
    "USER_GOALS_FILE_PATH = file_path_dict['user_goals']\n",
    "\n",
    "# Загрузка параметров запуска\n",
    "run_dict = constants['run']\n",
    "USE_USERSIM = run_dict['usersim']\n",
    "NUM_EP_TEST = run_dict['num_ep_run']\n",
    "MAX_ROUND_NUM = run_dict['max_round_num']\n",
    "\n",
    "# Загрузка базы данных\n",
    "database = pickle.load(open(DATABASE_FILE_PATH, 'rb'), encoding='latin1')\n",
    "\n",
    "# Чистка базы данных\n",
    "remove_empty_slots(database)\n",
    "\n",
    "# Загрузка словаря со всеми значениями\n",
    "db_dict = pickle.load(open(DICT_FILE_PATH, 'rb'), encoding='latin1')\n",
    "\n",
    "# Загрузка целей для пользовательской симуляции\n",
    "user_goals = pickle.load(open(USER_GOALS_FILE_PATH, 'rb'), encoding='latin1')\n",
    "\n",
    "# Инициализация объектов\n",
    "if USE_USERSIM:\n",
    "    user = UserSimulator(user_goals, constants, database)\n",
    "else:\n",
    "    user = User(constants)\n",
    "emc = ErrorModelController(db_dict, constants)\n",
    "state_tracker = StateTracker(database, constants)\n",
    "dqn_agent = DQNAgent(state_tracker.get_state_size(), constants)\n",
    "\n",
    "\n",
    "def test_run():\n",
    "    \n",
    "    \"\"\"\n",
    "    Запускает циул проверки агента.\n",
    "    Проверяет агента на goal-oriented задаче.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Тест начался...')\n",
    "    episode = 0\n",
    "    while episode < NUM_EP_TEST:\n",
    "        episode_reset()\n",
    "        episode += 1\n",
    "        ep_reward = 0\n",
    "        done = False\n",
    "        # Получает инициализирующее состояни для трекера состояния\n",
    "        state = state_tracker.get_state()\n",
    "        while not done:\n",
    "            # Агент выбирает действие \n",
    "            agent_action_index, agent_action = dqn_agent.get_action(state)\n",
    "            # Обновление трекера состояния действием агента\n",
    "            state_tracker.update_state_agent(agent_action)\n",
    "            print(agent_action)\n",
    "            # Пользователь делает действие\n",
    "            user_action, reward, done, success = user.step(agent_action)\n",
    "            ep_reward += reward\n",
    "            if not done:\n",
    "                # обавляет ошибку, если диалог не завершен\n",
    "                emc.infuse_error(user_action)\n",
    "            # Обновляет трекер состояния действием агента\n",
    "            state_tracker.update_state_user(user_action)\n",
    "            print(user_action)\n",
    "            # Берет следующее действие из состояния\n",
    "            state = state_tracker.get_state(done)\n",
    "        print('-'*50)\n",
    "        print(f'Эпизод: {episode} Успех: {success} Награда: {ep_reward}')\n",
    "        print('-'*50)\n",
    "    print('...Тест завершен')\n",
    "\n",
    "\n",
    "def episode_reset():\n",
    "    \"\"\"Перезапуск эпизода.\"\"\"\n",
    "\n",
    "    state_tracker.reset()\n",
    "    user_action = user.reset()\n",
    "    emc.infuse_error(user_action)\n",
    "    state_tracker.update_state_user(user_action)\n",
    "    dqn_agent.reset()\n",
    "\n",
    "\n",
    "test_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e201595",
   "metadata": {},
   "source": [
    "## Запуск в тестовом режиме"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d44557",
   "metadata": {},
   "source": [
    "### Примеры успешных диалогов\n",
    "\n",
    "###### 1\n",
    "\n",
    "Награда за раунд: 40\n",
    "\n",
    "{'intent': 'inform', 'inform_slots': {'время': '18:30'}, 'request_slots': {}, 'round': 1, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'inform', 'request_slots': {}, 'inform_slots': {'дата': 'завтра'}, 'round': 1, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'request', 'inform_slots': {}, 'request_slots': {'количество_человек': 'UNK'}, 'round': 2, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'inform', 'request_slots': {}, 'inform_slots': {'количество_человек': '3'}, 'round': 2, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'inform', 'inform_slots': {'район': 'текстильщики'}, 'request_slots': {}, 'round': 3, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'inform', 'request_slots': {}, 'inform_slots': {'город': 'москва'}, 'round': 3, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'match_found', 'inform_slots': {'город': 'москва', 'область': 'москва', 'кухня': 'итальянская', 'район': 'текстильщики', 'название': 'da pino', 'яндекс_карты': '4.4', 'гугл_карты': '4.4', 'дата': 'завтра', 'время': '18:30', 'количество_человек': '3', 'бронь': '25'}, 'request_slots': {}, 'round': 6, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'thanks', 'request_slots': {}, 'inform_slots': {}, 'round': 6, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'done', 'inform_slots': {}, 'request_slots': {}, 'round': 7, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'done', 'request_slots': {}, 'inform_slots': {}, 'round': 7, 'сприкер': 'Пользователь'}\n",
    "\n",
    "###### 2\n",
    "\n",
    "Награда за раунд: 33\n",
    "\n",
    "{'intent': 'inform', 'inform_slots': {'время': '19:00'}, 'request_slots': {}, 'round': 1, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'request', 'request_slots': {'дата': 'UNK'}, 'inform_slots': {}, 'round': 1, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'request', 'inform_slots': {}, 'request_slots': {'количество_человек': 'UNK'}, 'round': 2, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'inform', 'request_slots': {}, 'inform_slots': {'количество_человек': '4'}, 'round': 2, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'request', 'inform_slots': {}, 'request_slots': {'название': 'UNK'}, 'round': 3, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'inform', 'request_slots': {}, 'inform_slots': {'название': 'taksim'}, 'round': 3, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'inform', 'inform_slots': {'дата': 'сегодня'}, 'request_slots': {}, 'round': 4, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'inform', 'request_slots': {}, 'inform_slots': {'город': 'москва'}, 'round': 4, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'match_found', 'inform_slots': {'город': 'москва', 'область': 'москва', 'кухня': 'турецкий', 'район': 'чертаново', 'название': 'taksim', 'яндекс_карты': '4.6', 'гугл_карты': '4.4', 'дата': 'сегодня', 'время': '19:00', 'количество_человек': '4', 'бронь': '55'}, 'request_slots': {}, 'round': 5, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'thanks', 'request_slots': {}, 'inform_slots': {}, 'round': 5, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'done', 'inform_slots': {}, 'request_slots': {}, 'round': 6, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'done', 'request_slots': {}, 'inform_slots': {}, 'round': 6, 'сприкер': 'Пользователь'}\n",
    "\n",
    "###### 3\n",
    "\n",
    "Награда за раунд: 33\n",
    "\n",
    "{'intent': 'inform', 'inform_slots': {'время': '18:30'}, 'request_slots': {}, 'round': 1, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'inform', 'request_slots': {}, 'inform_slots': {'район': 'отрадное'}, 'round': 1, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'request', 'inform_slots': {}, 'request_slots': {'количество_человек': 'UNK'}, 'round': 2, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'inform', 'request_slots': {}, 'inform_slots': {'количество_человек': '3'}, 'round': 2, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'inform', 'inform_slots': {'дата': 'завтра'}, 'request_slots': {}, 'round': 3, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'inform', 'request_slots': {}, 'inform_slots': {'дата': 'сегодня'}, 'round': 3, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'inform', 'inform_slots': {'район': 'отрадное'}, 'request_slots': {}, 'round': 4, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'inform', 'request_slots': {}, 'inform_slots': {'город': 'москва'}, 'round': 4, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'inform', 'inform_slots': {'район': 'отрадное'}, 'request_slots': {}, 'round': 5, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'request', 'request_slots': {'бронь': 'UNK'}, 'inform_slots': {}, 'round': 5, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'match_found', 'inform_slots': {'город': 'москва', 'область': 'москва', 'кухня': 'итальянский', 'район': 'отрадное', 'название': 'osteria mario', 'яндекс_карты': '4.5', 'гугл_карты': '4.8', 'дата': 'сегодня', 'время': '18:30', 'количество_человек': '3', 'бронь': '24'}, 'request_slots': {}, 'round': 6, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'thanks', 'request_slots': {}, 'inform_slots': {}, 'round': 6, 'сприкер': 'Пользователь'}\n",
    "\n",
    "{'intent': 'done', 'inform_slots': {}, 'request_slots': {}, 'round': 7, 'спикер': 'Агент'}\n",
    "\n",
    "{'intent': 'done', 'request_slots': {}, 'inform_slots': {}, 'round': 7, 'сприкер': 'Пользователь'}"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Необработанный формат ячейки",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
